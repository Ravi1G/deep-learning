{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LSTM - Book Chapter Generator\n",
    "This notebook builds a LSTM Neural Network trained on \"Gjakftohtesia\" of the albanian author Ismail Kadare. It'll be used to generate a new chapter.The helper class and some parts of the code are from https://github.com/udacity/deep-learning/tree/master/tv-script-generation\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.3'), 'Please use TensorFlow version 1.3 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "data_dir = './data/Ismail Kadare - Gjakftohtesia.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Remove the first 90 characters, which contain general information\n",
    "text = text[90:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 25655\n",
      "Number of scenes: 2803\n",
      "Average number of sentences in each scene: 5.716018551551909\n",
      "Number of lines: 18825\n",
      "Average number of words in each line: 8.2532802124834\n",
      "\n",
      "The sentences 0 to 30:\n",
      " \n",
      "\n",
      "Silva e kaloi me shpejtesi sheshin e ministrive, megjithate, \n",
      "kur mberriti te hyrja e ministrise se saj, ishte \n",
      "pak vone. \n",
      "\n",
      "Pa e ngadalesuar ecjen, pershendeti nepunesin e \n",
      "sherbimit, fytyra e te cilit mezi dallohej pas xhamÂ•t te \n",
      "portinerise dhe ashtu, gjysme me vrap, nisi te ngjiste \n",
      "shkallet. \n",
      "\n",
      "Ne korridorin e katit te dyte desh u perplas me te \n",
      "njohurin e saj te dikurshem Viktor Hilen, te cilin s'e kishte \n",
      "takuar prej kohesh. \n",
      "\n",
      "\f",
      "\n",
      " O, si jeni?tha ajo, me frymemarrje akoma te \n",
      "shpeshuar nga ngjitja e shkalleve.C'ju ka sjelle kendej? \n",
      "Ai e veshtroi me ca sy te hutuar dhe vetem tani Silva \n",
      "vuri re ne fytyren e tij te parruar nje ndjenje lodhje-\n",
      "je dhe inerzie. \n",
      "\n",
      "Nje ngaterrese,ia beri ai neper dhembe, duke i \n",
      "shoqeruar fjalet me nje levizje te dores.Ku eshte zyra \n",
      "e zevendesministrit? \n",
      "Ju coj une,tha ajo.Ejani. \n",
      "Ajo eoi perpara, e lehtesuar qe mund te levizte. Megjithese \n",
      "tani e takonte rralle, ashtu si te gjithe te njohurit \n",
      "e tjere te perbashket te saj dhe te se motres, tani qe \n",
      "Ana s'ishte me, Silva si'llej me ta me shume kujdes, si me \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "view_sentence_range = (0, 30)\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    vocab = sorted(set(text))\n",
    "    vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "    int_to_vocab = dict(enumerate(vocab))\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tokenize Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    punctuation = {'.':'||Period||',\n",
    "                        ',': '||Comma||',\n",
    "                        '\"': '||Quotation_Mark||',\n",
    "                        ';': '||Semicolon||',\n",
    "                        '!': '||Exclamation_Mark||',\n",
    "                        '?': '||Question_Mark||',\n",
    "                        '(': '||Left_Parentheses||',\n",
    "                        ')': '||Right_Parentheses||',\n",
    "                        '--': '||Dash||',\n",
    "                        '\\n': '||Return||'}\n",
    "    return punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the Neural Network\n",
    "Following functions are going to be implemented:\n",
    "- get_inputs\n",
    "- get_init_cell\n",
    "- get_embed\n",
    "- build_rnn\n",
    "- build_nn\n",
    "- get_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input\n",
    "Creates a function which returns the placeholders for feeding the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    input = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    \n",
    "    return input, targets, learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_init_cell(batch_size, rnn_size, num_layers):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # Basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    \n",
    "    # Stack num_layers of basic lstm cells\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm for _ in range(num_layers)])\n",
    "    \n",
    "    # Initial state\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    initial_state = tf.identity(initial_state, name='initial_state')\n",
    "\n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "    final_state = tf.identity(final_state, name='final_state')\n",
    "    \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Add a fully connected layer on top of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    embed = get_embed(input_data, vocab_size, embed_dim)\n",
    "    outputs, final_state = build_rnn(cell, embed)\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, vocab_size, activation_fn=None)\n",
    "    \n",
    "    return logits, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    chars_per_batch = batch_size * seq_length\n",
    "    number_of_batches = len(int_text) // chars_per_batch\n",
    "    \n",
    "    xdata = int_text[: number_of_batches * chars_per_batch]\n",
    "    ydata = int_text[1: number_of_batches * chars_per_batch +1]\n",
    "    \n",
    "    xdata = np.array(xdata)\n",
    "    ydata = np.array(ydata)\n",
    "    \n",
    "    xdata = xdata.reshape(batch_size, -1)\n",
    "    ydata = ydata.reshape(batch_size, -1)\n",
    "    \n",
    "    x_batches = np.split(xdata, number_of_batches, axis=1)\n",
    "    y_batches = np.split(ydata, number_of_batches, axis=1)\n",
    "    \n",
    "    return np.array(list(zip(x_batches, y_batches)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204666\n"
     ]
    }
   ],
   "source": [
    "print(len(int_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 200\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "# RNN Size\n",
    "rnn_size = 512\n",
    "# Number of RNN layers\n",
    "num_layers = 2\n",
    "# Embedding Dimension Size\n",
    "embed_dim = 512\n",
    "# Sequence Length\n",
    "seq_length = 20\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 79\n",
    "# Directory for saving the model\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size, num_layers)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/79   train_loss = 9.690\n",
      "Epoch   1 Batch    0/79   train_loss = 6.401\n",
      "Epoch   2 Batch    0/79   train_loss = 6.297\n",
      "Epoch   3 Batch    0/79   train_loss = 6.203\n",
      "Epoch   4 Batch    0/79   train_loss = 6.113\n",
      "Epoch   5 Batch    0/79   train_loss = 5.959\n",
      "Epoch   6 Batch    0/79   train_loss = 5.781\n",
      "Epoch   7 Batch    0/79   train_loss = 5.660\n",
      "Epoch   8 Batch    0/79   train_loss = 5.572\n",
      "Epoch   9 Batch    0/79   train_loss = 5.487\n",
      "Epoch  10 Batch    0/79   train_loss = 5.429\n",
      "Epoch  11 Batch    0/79   train_loss = 5.335\n",
      "Epoch  12 Batch    0/79   train_loss = 5.278\n",
      "Epoch  13 Batch    0/79   train_loss = 5.181\n",
      "Epoch  14 Batch    0/79   train_loss = 5.092\n",
      "Epoch  15 Batch    0/79   train_loss = 5.061\n",
      "Epoch  16 Batch    0/79   train_loss = 4.942\n",
      "Epoch  17 Batch    0/79   train_loss = 4.872\n",
      "Epoch  18 Batch    0/79   train_loss = 4.799\n",
      "Epoch  19 Batch    0/79   train_loss = 4.696\n",
      "Epoch  20 Batch    0/79   train_loss = 4.588\n",
      "Epoch  21 Batch    0/79   train_loss = 4.529\n",
      "Epoch  22 Batch    0/79   train_loss = 4.434\n",
      "Epoch  23 Batch    0/79   train_loss = 4.325\n",
      "Epoch  24 Batch    0/79   train_loss = 4.198\n",
      "Epoch  25 Batch    0/79   train_loss = 4.097\n",
      "Epoch  26 Batch    0/79   train_loss = 4.025\n",
      "Epoch  27 Batch    0/79   train_loss = 3.883\n",
      "Epoch  28 Batch    0/79   train_loss = 3.770\n",
      "Epoch  29 Batch    0/79   train_loss = 3.664\n",
      "Epoch  30 Batch    0/79   train_loss = 3.608\n",
      "Epoch  31 Batch    0/79   train_loss = 3.471\n",
      "Epoch  32 Batch    0/79   train_loss = 3.395\n",
      "Epoch  33 Batch    0/79   train_loss = 3.285\n",
      "Epoch  34 Batch    0/79   train_loss = 3.149\n",
      "Epoch  35 Batch    0/79   train_loss = 3.078\n",
      "Epoch  36 Batch    0/79   train_loss = 2.943\n",
      "Epoch  37 Batch    0/79   train_loss = 2.808\n",
      "Epoch  38 Batch    0/79   train_loss = 2.728\n",
      "Epoch  39 Batch    0/79   train_loss = 2.599\n",
      "Epoch  40 Batch    0/79   train_loss = 2.493\n",
      "Epoch  41 Batch    0/79   train_loss = 2.484\n",
      "Epoch  42 Batch    0/79   train_loss = 2.325\n",
      "Epoch  43 Batch    0/79   train_loss = 2.195\n",
      "Epoch  44 Batch    0/79   train_loss = 2.059\n",
      "Epoch  45 Batch    0/79   train_loss = 1.956\n",
      "Epoch  46 Batch    0/79   train_loss = 1.928\n",
      "Epoch  47 Batch    0/79   train_loss = 1.895\n",
      "Epoch  48 Batch    0/79   train_loss = 1.742\n",
      "Epoch  49 Batch    0/79   train_loss = 1.681\n",
      "Epoch  50 Batch    0/79   train_loss = 1.568\n",
      "Epoch  51 Batch    0/79   train_loss = 1.496\n",
      "Epoch  52 Batch    0/79   train_loss = 1.412\n",
      "Epoch  53 Batch    0/79   train_loss = 1.387\n",
      "Epoch  54 Batch    0/79   train_loss = 1.240\n",
      "Epoch  55 Batch    0/79   train_loss = 1.192\n",
      "Epoch  56 Batch    0/79   train_loss = 1.145\n",
      "Epoch  57 Batch    0/79   train_loss = 1.073\n",
      "Epoch  58 Batch    0/79   train_loss = 1.006\n",
      "Epoch  59 Batch    0/79   train_loss = 0.949\n",
      "Epoch  60 Batch    0/79   train_loss = 0.911\n",
      "Epoch  61 Batch    0/79   train_loss = 0.840\n",
      "Epoch  62 Batch    0/79   train_loss = 0.811\n",
      "Epoch  63 Batch    0/79   train_loss = 0.793\n",
      "Epoch  64 Batch    0/79   train_loss = 0.711\n",
      "Epoch  65 Batch    0/79   train_loss = 0.692\n",
      "Epoch  66 Batch    0/79   train_loss = 0.643\n",
      "Epoch  67 Batch    0/79   train_loss = 0.582\n",
      "Epoch  68 Batch    0/79   train_loss = 0.588\n",
      "Epoch  69 Batch    0/79   train_loss = 0.525\n",
      "Epoch  70 Batch    0/79   train_loss = 0.497\n",
      "Epoch  71 Batch    0/79   train_loss = 0.474\n",
      "Epoch  72 Batch    0/79   train_loss = 0.481\n",
      "Epoch  73 Batch    0/79   train_loss = 0.414\n",
      "Epoch  74 Batch    0/79   train_loss = 0.404\n",
      "Epoch  75 Batch    0/79   train_loss = 0.393\n",
      "Epoch  76 Batch    0/79   train_loss = 0.364\n",
      "Epoch  77 Batch    0/79   train_loss = 0.365\n",
      "Epoch  78 Batch    0/79   train_loss = 0.369\n",
      "Epoch  79 Batch    0/79   train_loss = 0.335\n",
      "Epoch  80 Batch    0/79   train_loss = 0.309\n",
      "Epoch  81 Batch    0/79   train_loss = 0.296\n",
      "Epoch  82 Batch    0/79   train_loss = 0.299\n",
      "Epoch  83 Batch    0/79   train_loss = 0.283\n",
      "Epoch  84 Batch    0/79   train_loss = 0.277\n",
      "Epoch  85 Batch    0/79   train_loss = 0.277\n",
      "Epoch  86 Batch    0/79   train_loss = 0.264\n",
      "Epoch  87 Batch    0/79   train_loss = 0.256\n",
      "Epoch  88 Batch    0/79   train_loss = 0.254\n",
      "Epoch  89 Batch    0/79   train_loss = 0.254\n",
      "Epoch  90 Batch    0/79   train_loss = 0.250\n",
      "Epoch  91 Batch    0/79   train_loss = 0.247\n",
      "Epoch  92 Batch    0/79   train_loss = 0.244\n",
      "Epoch  93 Batch    0/79   train_loss = 0.243\n",
      "Epoch  94 Batch    0/79   train_loss = 0.241\n",
      "Epoch  95 Batch    0/79   train_loss = 0.241\n",
      "Epoch  96 Batch    0/79   train_loss = 0.240\n",
      "Epoch  97 Batch    0/79   train_loss = 0.239\n",
      "Epoch  98 Batch    0/79   train_loss = 0.235\n",
      "Epoch  99 Batch    0/79   train_loss = 0.233\n",
      "Epoch 100 Batch    0/79   train_loss = 0.231\n",
      "Epoch 101 Batch    0/79   train_loss = 0.230\n",
      "Epoch 102 Batch    0/79   train_loss = 0.230\n",
      "Epoch 103 Batch    0/79   train_loss = 0.229\n",
      "Epoch 104 Batch    0/79   train_loss = 0.227\n",
      "Epoch 105 Batch    0/79   train_loss = 0.226\n",
      "Epoch 106 Batch    0/79   train_loss = 0.225\n",
      "Epoch 107 Batch    0/79   train_loss = 0.225\n",
      "Epoch 108 Batch    0/79   train_loss = 0.225\n",
      "Epoch 109 Batch    0/79   train_loss = 0.225\n",
      "Epoch 110 Batch    0/79   train_loss = 0.225\n",
      "Epoch 111 Batch    0/79   train_loss = 0.228\n",
      "Epoch 112 Batch    0/79   train_loss = 0.226\n",
      "Epoch 113 Batch    0/79   train_loss = 0.229\n",
      "Epoch 114 Batch    0/79   train_loss = 0.230\n",
      "Epoch 115 Batch    0/79   train_loss = 0.228\n",
      "Epoch 116 Batch    0/79   train_loss = 0.223\n",
      "Epoch 117 Batch    0/79   train_loss = 0.223\n",
      "Epoch 118 Batch    0/79   train_loss = 0.222\n",
      "Epoch 119 Batch    0/79   train_loss = 0.225\n",
      "Epoch 120 Batch    0/79   train_loss = 0.229\n",
      "Epoch 121 Batch    0/79   train_loss = 0.238\n",
      "Epoch 122 Batch    0/79   train_loss = 0.262\n",
      "Epoch 123 Batch    0/79   train_loss = 0.287\n",
      "Epoch 124 Batch    0/79   train_loss = 0.302\n",
      "Epoch 125 Batch    0/79   train_loss = 0.297\n",
      "Epoch 126 Batch    0/79   train_loss = 0.262\n",
      "Epoch 127 Batch    0/79   train_loss = 0.226\n",
      "Epoch 128 Batch    0/79   train_loss = 0.218\n",
      "Epoch 129 Batch    0/79   train_loss = 0.215\n",
      "Epoch 130 Batch    0/79   train_loss = 0.213\n",
      "Epoch 131 Batch    0/79   train_loss = 0.212\n",
      "Epoch 132 Batch    0/79   train_loss = 0.211\n",
      "Epoch 133 Batch    0/79   train_loss = 0.210\n",
      "Epoch 134 Batch    0/79   train_loss = 0.210\n",
      "Epoch 135 Batch    0/79   train_loss = 0.209\n",
      "Epoch 136 Batch    0/79   train_loss = 0.209\n",
      "Epoch 137 Batch    0/79   train_loss = 0.209\n",
      "Epoch 138 Batch    0/79   train_loss = 0.209\n",
      "Epoch 139 Batch    0/79   train_loss = 0.209\n",
      "Epoch 140 Batch    0/79   train_loss = 0.209\n",
      "Epoch 141 Batch    0/79   train_loss = 0.209\n",
      "Epoch 142 Batch    0/79   train_loss = 0.209\n",
      "Epoch 143 Batch    0/79   train_loss = 0.209\n",
      "Epoch 144 Batch    0/79   train_loss = 0.208\n",
      "Epoch 145 Batch    0/79   train_loss = 0.208\n",
      "Epoch 146 Batch    0/79   train_loss = 0.207\n",
      "Epoch 147 Batch    0/79   train_loss = 0.208\n",
      "Epoch 148 Batch    0/79   train_loss = 0.207\n",
      "Epoch 149 Batch    0/79   train_loss = 0.208\n",
      "Epoch 150 Batch    0/79   train_loss = 0.208\n",
      "Epoch 151 Batch    0/79   train_loss = 0.208\n",
      "Epoch 152 Batch    0/79   train_loss = 0.208\n",
      "Epoch 153 Batch    0/79   train_loss = 0.208\n",
      "Epoch 154 Batch    0/79   train_loss = 0.208\n",
      "Epoch 155 Batch    0/79   train_loss = 0.209\n",
      "Epoch 156 Batch    0/79   train_loss = 0.209\n",
      "Epoch 157 Batch    0/79   train_loss = 0.209\n",
      "Epoch 158 Batch    0/79   train_loss = 0.208\n",
      "Epoch 159 Batch    0/79   train_loss = 0.208\n",
      "Epoch 160 Batch    0/79   train_loss = 0.208\n",
      "Epoch 161 Batch    0/79   train_loss = 0.206\n",
      "Epoch 162 Batch    0/79   train_loss = 0.207\n",
      "Epoch 163 Batch    0/79   train_loss = 0.208\n",
      "Epoch 164 Batch    0/79   train_loss = 0.208\n",
      "Epoch 165 Batch    0/79   train_loss = 0.208\n",
      "Epoch 166 Batch    0/79   train_loss = 0.208\n",
      "Epoch 167 Batch    0/79   train_loss = 0.207\n",
      "Epoch 168 Batch    0/79   train_loss = 0.207\n",
      "Epoch 169 Batch    0/79   train_loss = 0.206\n",
      "Epoch 170 Batch    0/79   train_loss = 0.206\n",
      "Epoch 171 Batch    0/79   train_loss = 0.207\n",
      "Epoch 172 Batch    0/79   train_loss = 0.206\n",
      "Epoch 173 Batch    0/79   train_loss = 0.207\n",
      "Epoch 174 Batch    0/79   train_loss = 0.207\n",
      "Epoch 175 Batch    0/79   train_loss = 0.207\n",
      "Epoch 176 Batch    0/79   train_loss = 0.206\n",
      "Epoch 177 Batch    0/79   train_loss = 0.205\n",
      "Epoch 178 Batch    0/79   train_loss = 0.204\n",
      "Epoch 179 Batch    0/79   train_loss = 0.205\n",
      "Epoch 180 Batch    0/79   train_loss = 0.206\n",
      "Epoch 181 Batch    0/79   train_loss = 0.204\n",
      "Epoch 182 Batch    0/79   train_loss = 0.204\n",
      "Epoch 183 Batch    0/79   train_loss = 0.205\n",
      "Epoch 184 Batch    0/79   train_loss = 0.204\n",
      "Epoch 185 Batch    0/79   train_loss = 0.204\n",
      "Epoch 186 Batch    0/79   train_loss = 0.204\n",
      "Epoch 187 Batch    0/79   train_loss = 0.203\n",
      "Epoch 188 Batch    0/79   train_loss = 0.204\n",
      "Epoch 189 Batch    0/79   train_loss = 0.204\n",
      "Epoch 190 Batch    0/79   train_loss = 0.212\n",
      "Epoch 191 Batch    0/79   train_loss = 0.484\n",
      "Epoch 192 Batch    0/79   train_loss = 0.485\n",
      "Epoch 193 Batch    0/79   train_loss = 0.312\n",
      "Epoch 194 Batch    0/79   train_loss = 0.225\n",
      "Epoch 195 Batch    0/79   train_loss = 0.209\n",
      "Epoch 196 Batch    0/79   train_loss = 0.204\n",
      "Epoch 197 Batch    0/79   train_loss = 0.203\n",
      "Epoch 198 Batch    0/79   train_loss = 0.202\n",
      "Epoch 199 Batch    0/79   train_loss = 0.202\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate Functions\n",
    "### Get Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \"\"\"\n",
    "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
    "    :param loaded_graph: TensorFlow graph loaded from file\n",
    "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
    "    \"\"\"\n",
    "    input = loaded_graph.get_tensor_by_name('input:0')\n",
    "    initial_state = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    final_state = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    probs = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    \n",
    "    return input, initial_state, final_state, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Choose Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word in the generated text\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    idx = np.random.choice(len(probabilities), 1, p=probabilities)[0]\n",
    "    return int_to_vocab[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "\n",
      " perseri perpiqej te shtrinte pushtetin e vet\n",
      "mbi dasmen, por terhiqej shpejt. dukej sikur daullja e\n",
      "ndillte dhe diana e mori duke u perpjekur te afrohej.\n",
      "ku u mbush as hyri, tha tjetri. kjo eshte keto?\n",
      "vrare gjithe shoqet.\n",
      "cfare?\n",
      "ajo beri nje karroce me nje cerek.\n",
      "te gjitha gjerat e vjetra, cili, jo vetem kur ai,\n",
      "duke afruar deren qe ajo te hapte syte.\n",
      "\n",
      "c'eshte me qetesi, perseriti shitesi, kur grinden?\n",
      "ku behet... thane se jam e kunderta, dhe ai nuk\n",
      "foli asgje.\n",
      "\n",
      "kurse une them se kam frike plotesisht, i thashe,\n",
      "\n",
      "te kujtohet menjehere atje dikush te drejte.\n",
      "\n",
      "\n",
      "poshte, kur tjetri u ngrit nga fusha, dhe midis librave dhe te\n",
      "tjereve, megjithate ne rrenoje iu duk gjithsesi e fundit, megjithese e ndjeu\n",
      "kete kohe te beri me qarte, nje si ata qe nuk u zhduk\n",
      "per te them se kete vajza, duke duket, me\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "gen_length = 200\n",
    "prime_word = 'perseri'\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word]\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    text = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        text = text.replace(' ' + token.lower(), key)\n",
    "    text = text.replace('\\n ', '\\n')\n",
    "    text = text.replace('( ', '(')\n",
    "        \n",
    "    print('\\n',text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
